change optimizer parameters group method change optimizer parameters group method add torch change isinstance method torch tensor parameter parameter freeze fix pep reformat freeze bug fix authored coauthoredby glenn jocher
hyp weight decay weightdecay total batch size totalbatchsize accumulate nbs scale weight decay weightdecay optimizer parameter groups model named parameters namedparameters requires grad requiresgrad true bias append biases elif weight append apply weight decay else append else model named modules namedmodules hasattr bias isinstance bias parameter append bias biases isinstance batch normd batchnormd append weight decay elif hasattr weight isinstance weight parameter append weight apply decay opt adam optimizer optim adam hyp betas hyp momentum adjust beta momentum
