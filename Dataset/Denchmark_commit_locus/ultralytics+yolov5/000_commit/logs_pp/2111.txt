torch cuda amp bug fix https github com ultralytics yolov pull introduced specific bug affects multi gpu multigpu trainings apparently cause using torch cuda amp decorator auto shape autoshape forward method implemented amp traditionally bug resolved
import torch import torch pil import image torch cuda import amp utils datasets import letterbox utils general import non max suppression nonmaxsuppression make divisible makedivisible scale coords scalecoords increment path incrementpath xyxyxywh
