update train
else append else hyp optimizer adam optimizer optim adam hyp betas hyp momentum use default beta adjust beta adam momentum per momentum adjustments https pytorch org docs stable modules torch optim scheduler lrscheduler html one cycle htmlonecyclelr hyp optimizer adam https pytorch org docs stable modules torch optim scheduler lrscheduler html one cycle htmlonecyclelr optimizer optim adam hyp betas hyp momentum adjust beta momentum else optimizer optim sgd hyp momentum hyp momentum nesterov true
