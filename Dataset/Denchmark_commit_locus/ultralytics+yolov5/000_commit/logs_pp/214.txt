comment updates
model optimizer amp initialize model optimizer opt level optlevel verbosity distributed training device type cpu torch cuda device count devicecount torch distributed available isavailable device type cpu torch cuda device count devicecount dist available isavailable dist init process group initprocessgroup backend nccl distributed backend init method initmethod tcp init method world size worldsize number nodes rank node rank model torch sync batch norm syncbatchnorm convert sync batchnorm convertsyncbatchnorm model device requires world size worldsize model torch parallel distributed data parallel distributeddataparallel model pip install torch torchvision https download pytorch org whl torch stable torchstable html trainloader dataloader dataset create dataloader createdataloader train path trainpath imgsz batch size batchsize opt
