      replace random_affine() with random_perspective()          Signed-off-by: Glenn Jocher <glenn.jocher@ultralytics.com> 
     return img, ratio, (dw, dh)     def random_affine(img, targets=(), degrees=10, translate=.1, scale=.1, shear=10, border=(0, 0)): def random_perspective(img, targets=(), degrees=10, translate=.1, scale=.1, shear=10, perspective=0.0, border=(0, 0)):      # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))     # https://medium.com/uruvideo/dataset-augmentation-with-random-homographies-a8f4b44830d4      # targets = [cls, xyxy]        height = img.shape[0] + border[0] * 2  # shape(h,w,c)      width = img.shape[1] + border[1] * 2       # Center     C = np.eye(3)     C[0, 2] = -img.shape[1] / 2  # x translation (pixels)     C[1, 2] = -img.shape[0] / 2  # y translation (pixels)      # Perspective     P = np.eye(3)     P[2, 0] = random.uniform(-perspective, perspective)  # x perspective (about y)     P[2, 1] = random.uniform(-perspective, perspective)  # y perspective (about x)       # Rotation and Scale      R = np.eye(3)      a = random.uniform(-degrees, degrees)      # a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations      s = random.uniform(1 - scale, 1 + scale)      # s = 2 ** random.uniform(-scale, scale)     R[:2] = cv2.getRotationMatrix2D(angle=a, center=(img.shape[1] / 2, img.shape[0] / 2), scale=s)      # Translation     T = np.eye(3)     T[0, 2] = random.uniform(-translate, translate) * img.shape[1] + border[1]  # x translation (pixels)     T[1, 2] = random.uniform(-translate, translate) * img.shape[0] + border[0]  # y translation (pixels)     R[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s)        # Shear      S = np.eye(3)      S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # x shear (deg)      S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # y shear (deg)       # Translation     T = np.eye(3)     T[0, 2] = random.uniform(0.5 - translate, 0.5 + translate) * width  # x translation (pixels)     T[1, 2] = random.uniform(0.5 - translate, 0.5 + translate) * height  # y translation (pixels)       # Combined rotation matrix     M = S @ T @ R  # ORDER IS IMPORTANT HERE!!     M = T @ S @ R @ P @ C  # order of operations (right to left) is IMPORTANT      if (border[0] != 0) or (border[1] != 0) or (M != np.eye(3)).any():  # image changed         img = cv2.warpAffine(img, M[:2], dsize=(width, height), flags=cv2.INTER_LINEAR, borderValue=(114, 114, 114))         if perspective:             img = cv2.warpPerspective(img, M, dsize=(width, height), borderValue=(114, 114, 114))         else:  # affine             img = cv2.warpAffine(img, M[:2], dsize=(width, height), borderValue=(114, 114, 114))      # Visualize     # import matplotlib.pyplot as plt     # ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel()     # ax[0].imshow(img[:, :, ::-1])  # base     # ax[1].imshow(img2[:, :, ::-1])  # warped        # Transform label coordinates      n = len(targets) 
