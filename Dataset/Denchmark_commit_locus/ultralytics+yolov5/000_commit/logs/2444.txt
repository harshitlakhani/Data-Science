      backbone as FP16, save default to FP32 
 def create_backbone(f='weights/best.pt', s='weights/backbone.pt'):  # from utils.utils import *; create_backbone()      # create backbone 's' from 'f'      device = torch.device('cpu')     x = torch.load(f, map_location=device)     torch.save(x, s)  # update model if SourceChangeWarning      x = torch.load(s, map_location=device)        x['optimizer'] = None      x['training_results'] = None      x['epoch'] = -1     x['model'].half()  # to FP16      for p in x['model'].parameters():          p.requires_grad = True      torch.save(x, s) 
