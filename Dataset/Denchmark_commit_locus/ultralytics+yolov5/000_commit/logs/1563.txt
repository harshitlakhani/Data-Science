      Fix DDP bug in single process multiple device use cases 
                                 world_size=1,  # number of nodes                                  rank=0)  # node rank          model = torch.nn.parallel.DistributedDataParallel(model)         # pip install torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html        # Dataset      dataset = LoadImagesAndLabels(train_path, imgsz, batch_size, 
