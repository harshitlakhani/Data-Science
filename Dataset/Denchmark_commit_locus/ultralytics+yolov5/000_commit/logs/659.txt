      Simplified inference (#1153) 
   class NMS(nn.Module):      # Non-Maximum Suppression (NMS) module     conf = 0.3  # confidence threshold     iou = 0.6  # IoU threshold     conf = 0.25  # confidence threshold     iou = 0.45  # IoU threshold      classes = None  # (optional list) filter by class       def __init__(self, dimension=1):     def __init__(self):          super(NMS, self).__init__()        def forward(self, x):          return non_max_suppression(x[0], conf_thres=self.conf, iou_thres=self.iou, classes=self.classes)     class autoShape(nn.Module):     # input-robust model wrapper for passing cv2/np/PIL/torch inputs. Includes preprocessing, inference and NMS     img_size = 640  # inference size (pixels)     conf = 0.25  # NMS confidence threshold     iou = 0.45  # NMS IoU threshold     classes = None  # (optional list) filter by class      def __init__(self, model):         super(autoShape, self).__init__()         self.model = model      def forward(self, x, size=640, augment=False, profile=False):         # supports inference from various sources. For height=720, width=1280, RGB images example inputs are:         #   opencv:     x = cv2.imread('image.jpg')[:,:,::-1]  # HWC BGR to RGB x(720,1280,3)         #   PIL:        x = Image.open('image.jpg')  # HWC x(720,1280,3)         #   numpy:      x = np.zeros((720,1280,3))  # HWC         #   torch:      x = torch.zeros(16,3,720,1280)  # BCHW         #   multiple:   x = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images          p = next(self.model.parameters())  # for device and type         if isinstance(x, torch.Tensor):  # torch             return self.model(x.to(p.device).type_as(p), augment, profile)  # inference          # Pre-process         if not isinstance(x, list):             x = [x]         shape0, shape1 = [], []  # image and inference shapes         batch = range(len(x))  # batch size         for i in batch:             x[i] = np.array(x[i])[:, :, :3]  # up to 3 channels if png             s = x[i].shape[:2]  # HWC             shape0.append(s)  # image shape             g = (size / max(s))  # gain             shape1.append([y * g for y in s])         shape1 = [make_divisible(x, int(self.stride.max())) for x in np.stack(shape1, 0).max(0)]  # inference shape         x = [letterbox(x[i], new_shape=shape1, auto=False)[0] for i in batch]  # pad         x = np.stack(x, 0) if batch[-1] else x[0][None]  # stack         x = np.ascontiguousarray(x.transpose((0, 3, 1, 2)))  # BHWC to BCHW         x = torch.from_numpy(x).to(p.device).type_as(p) / 255.  # uint8 to fp16/32          # Inference         x = self.model(x, augment, profile)  # forward         x = non_max_suppression(x[0], conf_thres=self.conf, iou_thres=self.iou, classes=self.classes)  # NMS          # Post-process         for i in batch:             if x[i] is not None:                 x[i][:, :4] = scale_coords(shape1, x[i][:, :4], shape0[i])         return x    class Flatten(nn.Module):      # Use after nn.AdaptiveAvgPool2d(1) to remove last 2 dimensions      @staticmethod 
