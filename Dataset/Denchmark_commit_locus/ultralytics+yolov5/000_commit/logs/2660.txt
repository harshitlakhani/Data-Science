      ONNX export bug fix #93 
       # Load pytorch model      google_utils.attempt_download(opt.weights)     model = torch.load(opt.weights, map_location=torch.device('cpu'))['model']     model = torch.load(opt.weights, map_location=torch.device('cpu'))['model'].float()      model.eval()      model.fuse()   
