      Refactor models/export.py arguments (#3564)          * Refactor models/export.py arguments          * cleanup          * cleanup 
 from utils.general import colorstr, check_img_size, check_requirements, file_size, set_logging  from utils.torch_utils import select_device   if __name__ == '__main__':     parser = argparse.ArgumentParser()     parser.add_argument('--weights', type=str, default='./yolov5s.pt', help='weights path')     parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='image size')  # height, width     parser.add_argument('--batch-size', type=int, default=1, help='batch size')     parser.add_argument('--device', default='cpu', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')     parser.add_argument('--include', nargs='+', default=['torchscript', 'onnx', 'coreml'], help='include formats')     parser.add_argument('--half', action='store_true', help='FP16 half-precision export')     parser.add_argument('--inplace', action='store_true', help='set YOLOv5 Detect() inplace=True')     parser.add_argument('--train', action='store_true', help='model.train() mode')     parser.add_argument('--optimize', action='store_true', help='optimize TorchScript for mobile')  # TorchScript-only     parser.add_argument('--dynamic', action='store_true', help='dynamic ONNX axes')  # ONNX-only     parser.add_argument('--simplify', action='store_true', help='simplify ONNX model')  # ONNX-only     parser.add_argument('--opset-version', type=int, default=12, help='ONNX opset version')  # ONNX-only     opt = parser.parse_args()     opt.img_size *= 2 if len(opt.img_size) == 1 else 1  # expand     opt.include = [x.lower() for x in opt.include]     print(opt)     set_logging()  def export(weights='./yolov5s.pt',  # weights path            img_size=(640, 640),  # image (height, width)            batch_size=1,  # batch size            device='cpu',  # cuda device, i.e. 0 or 0,1,2,3 or cpu            include=('torchscript', 'onnx', 'coreml'),  # include formats            half=False,  # FP16 half-precision export            inplace=False,  # set YOLOv5 Detect() inplace=True            train=False,  # model.train() mode            optimize=False,  # TorchScript: optimize for mobile            dynamic=False,  # ONNX: dynamic axes            simplify=False,  # ONNX: simplify model            opset_version=12,  # ONNX: opset version            ):      t = time.time()     include = [x.lower() for x in include]     img_size *= 2 if len(img_size) == 1 else 1  # expand        # Load PyTorch model     device = select_device(opt.device)     assert not (opt.device.lower() == 'cpu' and opt.half), '--half only compatible with GPU export, i.e. use --device 0'     model = attempt_load(opt.weights, map_location=device)  # load FP32 model     device = select_device(device)     assert not (device.type == 'cpu' and opt.half), '--half only compatible with GPU export, i.e. use --device 0'     model = attempt_load(weights, map_location=device)  # load FP32 model      labels = model.names        # Input      gs = int(max(model.stride))  # grid size (max stride)     opt.img_size = [check_img_size(x, gs) for x in opt.img_size]  # verify img_size are gs-multiples     img = torch.zeros(opt.batch_size, 3, *opt.img_size).to(device)  # image size(1,3,320,192) iDetection     img_size = [check_img_size(x, gs) for x in img_size]  # verify img_size are gs-multiples     img = torch.zeros(batch_size, 3, *img_size).to(device)  # image size(1,3,320,192) iDetection        # Update model     if opt.half:     if half:          img, model = img.half(), model.half()  # to FP16     model.train() if opt.train else model.eval()  # training mode = no Detect() layer grid construction     model.train() if train else model.eval()  # training mode = no Detect() layer grid construction      for k, m in model.named_modules():          m._non_persistent_buffers_set = set()  # pytorch 1.6.0 compatibility          if isinstance(m, models.common.Conv):  # assign export-friendly activations 
