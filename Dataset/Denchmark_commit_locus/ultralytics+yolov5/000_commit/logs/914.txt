      Fix redundant outputs via Logging in DDP training (#500)          * Change print to logging          * Clean function set_logging          * Add line spacing          * Change leftover prints to log          * Fix scanning labels output          * Fix rank naming          * Change leftover print to logging          * Reorganized DDP variables          * Fix type error          * Make quotes consistent          * Fix spelling          * Clean function call          * Add line spacing          * Update datasets.py          * Update train.py          Co-authored-by: Glenn Jocher <glenn.jocher@ultralytics.com> 
     if not opt.evolve:          tb_writer = None          if opt.global_rank in [-1, 0]:             print('Start Tensorboard with "tensorboard --logdir %s", view at http://localhost:6006/' % opt.logdir)             logger.info('Start Tensorboard with "tensorboard --logdir %s", view at http://localhost:6006/' % opt.logdir)              tb_writer = SummaryWriter(log_dir=increment_dir(Path(opt.logdir) / 'exp', opt.name))  # runs/exp            train(hyp, opt, device, tb_writer) 
