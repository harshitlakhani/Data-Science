      update train.py gsutil bucket fix (#463) 
       # Optimizer      nbs = 64  # nominal batch size     # the default DDP implementation is slow for accumulation according to: https://pytorch.org/docs/stable/notes/ddp.html     # default DDP implementation is slow for accumulation according to: https://pytorch.org/docs/stable/notes/ddp.html      # all-reduce operation is carried out during loss.backward().      # Thus, there would be redundant all-reduce communications in a accumulation procedure,      # which means, the result is still right but the training speed gets slower. 
