      autoShape() default for PyTorch Hub models (#1692)          * Add autoshape parameter          * Remove autoshape call in ReadMe          * Update hubconf.py          * file/URI inputs and autoshape check passthrough          Co-authored-by: Glenn Jocher <glenn.jocher@ultralytics.com> 
         super(autoShape, self).__init__()          self.model = model.eval()       def autoshape(self):         print('autoShape already enabled, skipping... ')  # model already converted to model.autoshape()         return self       def forward(self, imgs, size=640, augment=False, profile=False):         # supports inference from various sources. For height=720, width=1280, RGB images example inputs are:         #   opencv:     imgs = cv2.imread('image.jpg')[:,:,::-1]  # HWC BGR to RGB x(720,1280,3)         #   PIL:        imgs = Image.open('image.jpg')  # HWC x(720,1280,3)         #   numpy:      imgs = np.zeros((720,1280,3))  # HWC         #   torch:      imgs = torch.zeros(16,3,720,1280)  # BCHW         #   multiple:   imgs = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images         # Inference from various sources. For height=720, width=1280, RGB images example inputs are:         #   filename:   imgs = 'data/samples/zidane.jpg'         #   URI:             = 'https://github.com/ultralytics/yolov5/releases/download/v1.0/zidane.jpg'         #   OpenCV:          = cv2.imread('image.jpg')[:,:,::-1]  # HWC BGR to RGB x(720,1280,3)         #   PIL:             = Image.open('image.jpg')  # HWC x(720,1280,3)         #   numpy:           = np.zeros((720,1280,3))  # HWC         #   torch:           = torch.zeros(16,3,720,1280)  # BCHW         #   multiple:        = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images            p = next(self.model.parameters())  # for device and type          if isinstance(imgs, torch.Tensor):  # torch              return self.model(imgs.to(p.device).type_as(p), augment, profile)  # inference            # Pre-process         if not isinstance(imgs, list):             imgs = [imgs]         n, imgs = (len(imgs), imgs) if isinstance(imgs, list) else (1, [imgs])  # number of images, list of images          shape0, shape1 = [], []  # image and inference shapes         batch = range(len(imgs))  # batch size         for i in batch:             imgs[i] = np.array(imgs[i])  # to numpy             if imgs[i].shape[0] < 5:  # image in CHW                 imgs[i] = imgs[i].transpose((1, 2, 0))  # reverse dataloader .transpose(2, 0, 1)             imgs[i] = imgs[i][:, :, :3] if imgs[i].ndim == 3 else np.tile(imgs[i][:, :, None], 3)  # enforce 3ch input             s = imgs[i].shape[:2]  # HWC         for i, im in enumerate(imgs):             if isinstance(im, str):  # filename or uri                 im = Image.open(requests.get(im, stream=True).raw if im.startswith('http') else im)  # open             im = np.array(im)  # to numpy             if im.shape[0] < 5:  # image in CHW                 im = im.transpose((1, 2, 0))  # reverse dataloader .transpose(2, 0, 1)             im = im[:, :, :3] if im.ndim == 3 else np.tile(im[:, :, None], 3)  # enforce 3ch input             s = im.shape[:2]  # HWC              shape0.append(s)  # image shape              g = (size / max(s))  # gain              shape1.append([y * g for y in s])             imgs[i] = im  # update          shape1 = [make_divisible(x, int(self.stride.max())) for x in np.stack(shape1, 0).max(0)]  # inference shape         x = [letterbox(imgs[i], new_shape=shape1, auto=False)[0] for i in batch]  # pad         x = np.stack(x, 0) if batch[-1] else x[0][None]  # stack         x = [letterbox(im, new_shape=shape1, auto=False)[0] for im in imgs]  # pad         x = np.stack(x, 0) if n > 1 else x[0][None]  # stack          x = np.ascontiguousarray(x.transpose((0, 3, 1, 2)))  # BHWC to BCHW          x = torch.from_numpy(x).to(p.device).type_as(p) / 255.  # uint8 to fp16/32   
