      single command --resume (#756)          * single command --resume          * else check files, remove TODO          * argparse.Namespace()          * tensorboard lr          * bug fix in get_latest_run() 
         model = DDP(model, device_ids=[opt.local_rank], output_device=(opt.local_rank))        # Trainloader     dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt, hyp=hyp, augment=True,                                             cache=opt.cache_images, rect=opt.rect, rank=rank,     dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,                                             hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect, rank=rank,                                              world_size=opt.world_size, workers=opt.workers)      mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class      nb = len(dataloader)  # number of batches     ema.updates = start_epoch * nb // accumulate  # set EMA updates      assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Possible class labels are 0-%g' % (mlc, nc, opt.data, nc - 1)        # Testloader      if rank in [-1, 0]:         # local_rank is set to -1. Because only the first process is expected to do evaluation.         testloader = create_dataloader(test_path, imgsz_test, total_batch_size, gs, opt, hyp=hyp, augment=False,                                        cache=opt.cache_images, rect=True, rank=-1, world_size=opt.world_size,                                        workers=opt.workers)[0]         testloader = create_dataloader(test_path, imgsz_test, total_batch_size, gs, opt,                                        hyp=hyp, augment=False, cache=opt.cache_images, rect=True, rank=-1,                                        world_size=opt.world_size, workers=opt.workers)[0]  # only runs on process 0        # Model parameters      hyp['cls'] *= nc / 80.  # scale coco-tuned hyp['cls'] to current dataset 
