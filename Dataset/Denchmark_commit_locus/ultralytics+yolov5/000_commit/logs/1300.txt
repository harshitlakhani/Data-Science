      Linear LR scheduler option (#2150)          * Linear LR scheduler option          * Update train.py 
       # Scheduler https://arxiv.org/pdf/1812.01187.pdf      # https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#OneCycleLR     lf = one_cycle(1, hyp['lrf'], epochs)  # cosine 1->hyp['lrf']     if opt.linear_lr:         lf = lambda x: (1 - x / (epochs - 1)) * (1.0 - hyp['lrf']) + hyp['lrf']  # linear     else:         lf = one_cycle(1, hyp['lrf'], epochs)  # cosine 1->hyp['lrf']      scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)      # plot_lr_scheduler(optimizer, scheduler, epochs)   
