      test during training default to FP16 
         if device.type != 'cpu' and torch.cuda.device_count() > 1:              model = nn.DataParallel(model)           training = False      else:  # called by train.py         device = next(model.parameters()).device  # get model device         half = False          training = True         device = next(model.parameters()).device  # get model device         half = device.type != 'cpu'  # half precision only supported on CUDA         if half:             model.half()  # to FP16        # Configure      model.eval() 
