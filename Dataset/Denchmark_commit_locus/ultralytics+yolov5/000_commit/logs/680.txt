      Single-source training (#680)          * Single-source training          * Extract hyperparameters into seperate files          * weight decay scientific notation yaml reader bug fix          * remove import glob          * intersect_dicts() implementation          * 'or' bug fix          * .to(device) bug fix 
     opt.weights = last if opt.resume and not opt.weights else opt.weights      if opt.local_rank == -1 or ("RANK" in os.environ and os.environ["RANK"] == "0"):          check_git_status()     opt.cfg = check_file(opt.cfg)  # check file     opt.data = check_file(opt.data)  # check file     if opt.hyp:  # update hyps         opt.hyp = check_file(opt.hyp)  # check file         with open(opt.hyp) as f:             hyp.update(yaml.load(f, Loader=yaml.FullLoader))  # update hyps      opt.data, opt.cfg, opt.hyp = check_file(opt.data), check_file(opt.cfg), check_file(opt.hyp)  # check files     assert len(opt.cfg) or len(opt.weights), 'either --cfg or --weights must be specified'     assert len(opt.hyp), '--hyp must be specified'       opt.img_size.extend([opt.img_size[-1]] * (2 - len(opt.img_size)))  # extend to 2 sizes (train, test)      device = select_device(opt.device, batch_size=opt.batch_size)      opt.total_batch_size = opt.batch_size      opt.world_size = 1      opt.global_rank = -1            # DDP mode      if opt.local_rank != -1:          assert torch.cuda.device_count() > opt.local_rank 
