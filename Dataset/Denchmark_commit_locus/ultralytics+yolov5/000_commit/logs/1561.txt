      Increase FLOPS robustness (#1608) 
       try:  # FLOPS          from thop import profile         stride = int(model.stride.max())         stride = int(model.stride.max()) if hasattr(model, 'stride') else 32          img = torch.zeros((1, 3, stride, stride), device=next(model.parameters()).device)  # input          flops = profile(deepcopy(model), inputs=(img,), verbose=False)[0] / 1E9 * 2  # stride FLOPS          img_size = img_size if isinstance(img_size, list) else [img_size, img_size]  # expand if int/float 
