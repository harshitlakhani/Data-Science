      Eliminate `total_batch_size` variable (#3697)          * Eliminate `total_batch_size` variable          * cleanup          * Update train.py 
         assert os.path.isfile(ckpt), 'ERROR: --resume checkpoint does not exist'          with open(Path(ckpt).parent.parent / 'opt.yaml') as f:              opt = argparse.Namespace(**yaml.safe_load(f))  # replace         opt.cfg, opt.weights, opt.resume, opt.batch_size = '', ckpt, True, opt.total_batch_size  # reinstate         opt.cfg, opt.weights, opt.resume = '', ckpt, True  # reinstate          logger.info('Resuming training from %s' % ckpt)      else:          # opt.hyp = opt.hyp or ('hyp.finetune.yaml' if opt.weights else 'hyp.scratch.yaml') 
