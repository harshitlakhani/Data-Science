      update build_targets() (#589)          Signed-off-by: Glenn Jocher <glenn.jocher@ultralytics.com> 
   def compute_loss(p, targets, model):  # predictions, targets, model      device = targets.device     ft = torch.cuda.FloatTensor if p[0].is_cuda else torch.Tensor     lcls, lbox, lobj = ft([0]).to(device), ft([0]).to(device), ft([0]).to(device)     lcls, lbox, lobj = torch.zeros(3, 1, device=device)      tcls, tbox, indices, anchors = build_targets(p, targets, model)  # targets      h = model.hyp  # hyperparameters     red = 'mean'  # Loss reduction (sum or mean)        # Define criteria     BCEcls = nn.BCEWithLogitsLoss(pos_weight=ft([h['cls_pw']]), reduction=red).to(device)     BCEobj = nn.BCEWithLogitsLoss(pos_weight=ft([h['obj_pw']]), reduction=red).to(device)     BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([h['cls_pw']])).to(device)     BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([h['obj_pw']])).to(device)       # class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3     # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3      cp, cn = smooth_BCE(eps=0.0)       # focal loss     # Focal loss      g = h['fl_gamma']  # focal loss gamma      if g > 0:          BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)       # per output     # Losses      nt = 0  # number of targets      np = len(p)  # number of outputs      balance = [4.0, 1.0, 0.4] if np == 3 else [4.0, 1.0, 0.4, 0.1]  # P3-5 or P3-6      for i, pi in enumerate(p):  # layer index, layer predictions          b, a, gj, gi = indices[i]  # image, anchor, gridy, gridx         tobj = torch.zeros_like(pi[..., 0]).to(device)  # target obj         tobj = torch.zeros_like(pi[..., 0], device=device)  # target obj           nb = b.shape[0]  # number of targets         if nb:             nt += nb  # cumulative targets         n = b.shape[0]  # number of targets         if n:             nt += n  # cumulative targets              ps = pi[b, a, gj, gi]  # prediction subset corresponding to targets               # GIoU             # Regression              pxy = ps[:, :2].sigmoid() * 2. - 0.5              pwh = (ps[:, 2:4].sigmoid() * 2) ** 2 * anchors[i]              pbox = torch.cat((pxy, pwh), 1).to(device)  # predicted box             giou = bbox_iou(pbox.t(), tbox[i], x1y1x2y2=False, GIoU=True)  # giou(prediction, target)             lbox += (1.0 - giou).sum() if red == 'sum' else (1.0 - giou).mean()  # giou loss             giou = bbox_iou(pbox.T, tbox[i], x1y1x2y2=False, CIoU=True)  # giou(prediction, target)             lbox += (1.0 - giou).mean()  # giou loss               # Obj             # Objectness              tobj[b, a, gj, gi] = (1.0 - model.gr) + model.gr * giou.detach().clamp(0).type(tobj.dtype)  # giou ratio               # Class             # Classification              if model.nc > 1:  # cls loss (only if multiple classes)                 t = torch.full_like(ps[:, 5:], cn).to(device)  # targets                 t[range(nb), tcls[i]] = cp                 lcls += BCEcls(ps[:, 5:], t)  # BCE                 t = torch.full_like(ps[:, 5:], cn, device=device)  # targets                 t[range(n), tcls[i]] = cp                 lcls = lcls + BCEcls(ps[:, 5:], t)  # BCE                # Append targets to text file              # with open('targets.txt', 'a') as file:              #     [file.write('%11.5g ' * 4 % tuple(x) + '\n') for x in torch.cat((txy[i], twh[i]), 1)]           lobj += BCEobj(pi[..., 4], tobj) * balance[i]  # obj loss         lobj = lobj + BCEobj(pi[..., 4], tobj) * balance[i]  # obj loss        s = 3 / np  # output count scaling      lbox *= h['giou'] * s      lobj *= h['obj'] * s * (1.4 if np == 4 else 1.)      lcls *= h['cls'] * s      bs = tobj.shape[0]  # batch size     if red == 'sum':         g = 3.0  # loss gain         lobj *= g / bs         if nt:             lcls *= g / nt / model.nc             lbox *= g / nt        loss = lbox + lobj + lcls      return loss * bs, torch.cat((lbox, lobj, lcls, loss)).detach() 
