      PyTorch version to screen and cleanup (#1325)          * Create flatten_recursive() helper function          * cleanup          * print torch version 
         if ng > 1 and batch_size:  # check that batch_size is compatible with device_count              assert batch_size % ng == 0, 'batch-size %g not multiple of GPU count %g' % (batch_size, ng)          x = [torch.cuda.get_device_properties(i) for i in range(ng)]         s = 'Using CUDA '         s = f'Using torch {torch.__version__} '          for i in range(0, ng):              if i == 1:                  s = ' ' * len(s)             logger.info("%sdevice%g _CudaDeviceProperties(name='%s', total_memory=%dMB)" %                         (s, i, x[i].name, x[i].total_memory / c))             logger.info("%sCUDA:%g (%s, %dMB)" % (s, i, x[i].name, x[i].total_memory / c))      else:         logger.info('Using CPU')         logger.info(f'Using torch {torch.__version__} CPU')        logger.info('')  # skip a line      return torch.device('cuda:0' if cuda else 'cpu') 
