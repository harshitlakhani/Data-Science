      Improved model+EMA checkpointing (#2292)          * Enhanced model+EMA checkpointing          * update          * bug fix          * bug fix 2          * always save optimizer          * ema half          * remove model.float()          * model half          * carry ema/model in fp32          * rm model.float()          * both to float always          * cleanup          * cleanup 
                 if best_fitness == fi:                      torch.save(ckpt, best)                  del ckpt              model.float(), ema.ema.float()           # end epoch ----------------------------------------------------------------------------------------------------      # end training   
