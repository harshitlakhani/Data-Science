      Improved model+EMA checkpointing (#2292)          * Enhanced model+EMA checkpointing          * update          * bug fix          * bug fix 2          * always save optimizer          * ema half          * remove model.float()          * model half          * carry ema/model in fp32          * rm model.float()          * both to float always          * cleanup          * cleanup 
 from utils.google_utils import attempt_download  from utils.loss import ComputeLoss  from utils.plots import plot_images, plot_labels, plot_results, plot_evolution from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel    logger = logging.getLogger(__name__)   
