      Add `train.run()` method (#3700)          * Update train.py explicit arguments          * Update train.py          * Add run method 
                         'ema': deepcopy(ema.ema).half(),                          'updates': ema.updates,                          'optimizer': optimizer.state_dict(),                         'wandb_id': wandb_logger.wandb_run.id if wandb_logger.wandb else None}                         'wandb_id': wandb_logger.wandb_run.id if loggers['wandb'] else None}                    # Save last, best and delete                  torch.save(ckpt, last)                  if best_fitness == fi:                      torch.save(ckpt, best)                 if wandb_logger.wandb:                 if loggers['wandb']:                      if ((epoch + 1) % opt.save_period == 0 and not final_epoch) and opt.save_period != -1:                          wandb_logger.log_model(last.parent, opt, epoch, fi, best_model=best_fitness == fi)                  del ckpt 
