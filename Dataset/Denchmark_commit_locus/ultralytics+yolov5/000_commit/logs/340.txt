      W&B DDP fix (#2574) 
     is_coco = opt.data.endswith('coco.yaml')        # Logging- Doing this before checking the dataset. Might update data_dict     loggers = {'wandb': None}  # loggers dict      if rank in [-1, 0]:          opt.hyp = hyp  # add hyperparameters          run_id = torch.load(weights).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None          wandb_logger = WandbLogger(opt, Path(opt.save_dir).stem, run_id, data_dict)         loggers['wandb'] = wandb_logger.wandb          data_dict = wandb_logger.data_dict          if wandb_logger.wandb:              weights, epochs, hyp = opt.weights, opt.epochs, opt.hyp  # WandbLogger might update weights, epochs if resuming     loggers = {'wandb': wandb_logger.wandb}  # loggers dict           nc = 1 if opt.single_cls else int(data_dict['nc'])  # number of classes      names = ['item'] if opt.single_cls and len(data_dict['names']) != 1 else data_dict['names']  # class names      assert len(names) == nc, '%g names found for nc=%g dataset in %s' % (len(names), nc, opt.data)  # check 
