      refactor dataloader 
         model = torch.nn.parallel.DistributedDataParallel(model)          # pip install torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html       # Dataset     dataset = LoadImagesAndLabels(train_path, imgsz, batch_size,                                   augment=True,                                   hyp=hyp,  # augmentation hyperparameters                                   rect=opt.rect,  # rectangular training                                   cache_images=opt.cache_images,                                   single_cls=opt.single_cls,                                   stride=gs)     # Trainloader     dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,                                             hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect)      mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class      assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Correct your labels or your model.' % (mlc, nc, opt.cfg)       # Dataloader     batch_size = min(batch_size, len(dataset))     nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers     dataloader = torch.utils.data.DataLoader(dataset,                                              batch_size=batch_size,                                              num_workers=nw,                                              shuffle=not opt.rect,  # Shuffle=True unless rectangular training is used                                              pin_memory=True,                                              collate_fn=dataset.collate_fn)       # Testloader     testloader = torch.utils.data.DataLoader(LoadImagesAndLabels(test_path, imgsz_test, batch_size,                                                                  hyp=hyp,                                                                  rect=True,                                                                  cache_images=opt.cache_images,                                                                  single_cls=opt.single_cls,                                                                  stride=gs),                                              batch_size=batch_size,                                              num_workers=nw,                                              pin_memory=True,                                              collate_fn=dataset.collate_fn)     testloader = create_dataloader(test_path, imgsz_test, batch_size, gs, opt,                                             hyp=hyp, augment=False, cache=opt.cache_images, rect=True)[0]        # Model parameters      hyp['cls'] *= nc / 80.  # scale coco-tuned hyp['cls'] to current dataset 
