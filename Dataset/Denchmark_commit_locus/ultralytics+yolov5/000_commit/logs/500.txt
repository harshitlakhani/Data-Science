      FP16 inference update 
     # Run inference      t0 = time.time()      img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img     _ = model(img.half() if half else img.float()) if device.type != 'cpu' else None  # run once     _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once      for path, img, im0s, vid_cap in dataset:          img = torch.from_numpy(img).to(device)          img = img.half() if half else img.float()  # uint8 to fp16/32 
