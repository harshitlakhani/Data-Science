      Utils reorganization (#1392)          * Utils reorganization          * Add new utils files          * cleanup          * simplify          * reduce datasets.py          * remove evolve.sh          * loadWebcam cleanup 
     print('Optimizer stripped from %s,%s %.1fMB' % (f, (' saved as %s,' % s) if s else '', mb))     def coco_class_count(path='../coco/labels/train2014/'):     # Histogram of occurrences per class     nc = 80  # number classes     x = np.zeros(nc, dtype='int32')     files = sorted(glob.glob('%s/*.*' % path))     for i, file in enumerate(files):         labels = np.loadtxt(file, dtype=np.float32).reshape(-1, 5)         x += np.bincount(labels[:, 0].astype('int32'), minlength=nc)         print(i, len(files))   def coco_only_people(path='../coco/labels/train2017/'):  # from utils.general import *; coco_only_people()     # Find images with only people     files = sorted(glob.glob('%s/*.*' % path))     for i, file in enumerate(files):         labels = np.loadtxt(file, dtype=np.float32).reshape(-1, 5)         if all(labels[:, 0] == 0):             print(labels.shape[0], file)   def crop_images_random(path='../images/', scale=0.50):  # from utils.general import *; crop_images_random()     # crops images into random squares up to scale fraction     # WARNING: overwrites images!     for file in tqdm(sorted(glob.glob('%s/*.*' % path))):         img = cv2.imread(file)  # BGR         if img is not None:             h, w = img.shape[:2]              # create random mask             a = 30  # minimum size (pixels)             mask_h = random.randint(a, int(max(a, h * scale)))  # mask height             mask_w = mask_h  # mask width              # box             xmin = max(0, random.randint(0, w) - mask_w // 2)             ymin = max(0, random.randint(0, h) - mask_h // 2)             xmax = min(w, xmin + mask_w)             ymax = min(h, ymin + mask_h)              # apply random color mask             cv2.imwrite(file, img[ymin:ymax, xmin:xmax])   def coco_single_class_labels(path='../coco/labels/train2014/', label_class=43):     # Makes single-class coco datasets. from utils.general import *; coco_single_class_labels()     if os.path.exists('new/'):         shutil.rmtree('new/')  # delete output folder     os.makedirs('new/')  # make new output folder     os.makedirs('new/labels/')     os.makedirs('new/images/')     for file in tqdm(sorted(glob.glob('%s/*.*' % path))):         with open(file, 'r') as f:             labels = np.array([x.split() for x in f.read().splitlines()], dtype=np.float32)         i = labels[:, 0] == label_class         if any(i):             img_file = file.replace('labels', 'images').replace('txt', 'jpg')             labels[:, 0] = 0  # reset class to 0             with open('new/images.txt', 'a') as f:  # add image to dataset list                 f.write(img_file + '\n')             with open('new/labels/' + Path(file).name, 'a') as f:  # write label                 for l in labels[i]:                     f.write('%g %.6f %.6f %.6f %.6f\n' % tuple(l))             shutil.copyfile(src=img_file, dst='new/images/' + Path(file).name.replace('txt', 'jpg'))  # copy images   def kmean_anchors(path='./data/coco128.yaml', n=9, img_size=640, thr=4.0, gen=1000, verbose=True):     """ Creates kmeans-evolved anchors from training dataset          Arguments:             path: path to dataset *.yaml, or a loaded dataset             n: number of anchors             img_size: image size used for training             thr: anchor-label wh ratio threshold hyperparameter hyp['anchor_t'] used for training, default=4.0             gen: generations to evolve anchors using genetic algorithm          Return:             k: kmeans evolved anchors          Usage:             from utils.general import *; _ = kmean_anchors()     """     thr = 1. / thr      def metric(k, wh):  # compute metrics         r = wh[:, None] / k[None]         x = torch.min(r, 1. / r).min(2)[0]  # ratio metric         # x = wh_iou(wh, torch.tensor(k))  # iou metric         return x, x.max(1)[0]  # x, best_x      def fitness(k):  # mutation fitness         _, best = metric(torch.tensor(k, dtype=torch.float32), wh)         return (best * (best > thr).float()).mean()  # fitness      def print_results(k):         k = k[np.argsort(k.prod(1))]  # sort small to large         x, best = metric(k, wh0)         bpr, aat = (best > thr).float().mean(), (x > thr).float().mean() * n  # best possible recall, anch > thr         print('thr=%.2f: %.4f best possible recall, %.2f anchors past thr' % (thr, bpr, aat))         print('n=%g, img_size=%s, metric_all=%.3f/%.3f-mean/best, past_thr=%.3f-mean: ' %               (n, img_size, x.mean(), best.mean(), x[x > thr].mean()), end='')         for i, x in enumerate(k):             print('%i,%i' % (round(x[0]), round(x[1])), end=',  ' if i < len(k) - 1 else '\n')  # use in *.cfg         return k      if isinstance(path, str):  # *.yaml file         with open(path) as f:             data_dict = yaml.load(f, Loader=yaml.FullLoader)  # model dict         from utils.datasets import LoadImagesAndLabels         dataset = LoadImagesAndLabels(data_dict['train'], augment=True, rect=True)     else:         dataset = path  # dataset      # Get label wh     shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)     wh0 = np.concatenate([l[:, 3:5] * s for s, l in zip(shapes, dataset.labels)])  # wh      # Filter     i = (wh0 < 3.0).any(1).sum()     if i:         print('WARNING: Extremely small objects found. '               '%g of %g labels are < 3 pixels in width or height.' % (i, len(wh0)))     wh = wh0[(wh0 >= 2.0).any(1)]  # filter > 2 pixels      # Kmeans calculation     print('Running kmeans for %g anchors on %g points...' % (n, len(wh)))     s = wh.std(0)  # sigmas for whitening     k, dist = kmeans(wh / s, n, iter=30)  # points, mean distance     k *= s     wh = torch.tensor(wh, dtype=torch.float32)  # filtered     wh0 = torch.tensor(wh0, dtype=torch.float32)  # unfiltered     k = print_results(k)      # Plot     # k, d = [None] * 20, [None] * 20     # for i in tqdm(range(1, 21)):     #     k[i-1], d[i-1] = kmeans(wh / s, i)  # points, mean distance     # fig, ax = plt.subplots(1, 2, figsize=(14, 7))     # ax = ax.ravel()     # ax[0].plot(np.arange(1, 21), np.array(d) ** 2, marker='.')     # fig, ax = plt.subplots(1, 2, figsize=(14, 7))  # plot wh     # ax[0].hist(wh[wh[:, 0]<100, 0],400)     # ax[1].hist(wh[wh[:, 1]<100, 1],400)     # fig.tight_layout()     # fig.savefig('wh.png', dpi=200)      # Evolve     npr = np.random     f, sh, mp, s = fitness(k), k.shape, 0.9, 0.1  # fitness, generations, mutation prob, sigma     pbar = tqdm(range(gen), desc='Evolving anchors with Genetic Algorithm')  # progress bar     for _ in pbar:         v = np.ones(sh)         while (v == 1).all():  # mutate until a change occurs (prevent duplicates)             v = ((npr.random(sh) < mp) * npr.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)         kg = (k.copy() * v).clip(min=2.0)         fg = fitness(kg)         if fg > f:             f, k = fg, kg.copy()             pbar.desc = 'Evolving anchors with Genetic Algorithm: fitness = %.4f' % f             if verbose:                 print_results(k)      return print_results(k)    def print_mutation(hyp, results, yaml_file='hyp_evolved.yaml', bucket=''):      # Print mutation results to evolve.txt (for use with train.py --evolve)      a = '%10s' * len(hyp) % tuple(hyp.keys())  # hyperparam keys 
