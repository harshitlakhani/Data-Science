      Unified '/project/name' results saving (#1377)          * Project/name update          * Update ci-testing.yml          * address project with path separator failure mode          * Project/name update          * address project with path separator failure mode          * Update ci-testing.yml          * detect.py default --name bug fix          * missing rstrip PR          * train/exp0 to train/exp 
     # Resume      if opt.resume:  # resume an interrupted run          ckpt = opt.resume if isinstance(opt.resume, str) else get_latest_run()  # specified or most recent path         log_dir = Path(ckpt).parent.parent  # runs/train/exp0         opt.save_dir = Path(ckpt).parent.parent  # runs/train/exp          assert os.path.isfile(ckpt), 'ERROR: --resume checkpoint does not exist'         with open(log_dir / 'opt.yaml') as f:         with open(opt.save_dir / 'opt.yaml') as f:              opt = argparse.Namespace(**yaml.load(f, Loader=yaml.FullLoader))  # replace          opt.cfg, opt.weights, opt.resume = '', ckpt, True          logger.info('Resuming training from %s' % ckpt)       else:          # opt.hyp = opt.hyp or ('hyp.finetune.yaml' if opt.weights else 'hyp.scratch.yaml')          opt.data, opt.cfg, opt.hyp = check_file(opt.data), check_file(opt.cfg), check_file(opt.hyp)  # check files          assert len(opt.cfg) or len(opt.weights), 'either --cfg or --weights must be specified'          opt.img_size.extend([opt.img_size[-1]] * (2 - len(opt.img_size)))  # extend to 2 sizes (train, test)         log_dir = increment_dir(Path(opt.logdir) / 'exp', opt.name)  # runs/exp1         opt.name = 'evolve' if opt.evolve else opt.name         opt.save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run        # DDP mode      device = select_device(opt.device, batch_size=opt.batch_size) 
