      Improved W&B integration  (#2125)          * Init Commit          * new wandb integration          * Update          * Use data_dict in test          * Updates          * Update: scope of log_img          * Update: scope of log_img          * Update          * Update: Fix logging conditions          * Add tqdm bar, support for .txt dataset format          * Improve Result table Logger          * Init Commit          * new wandb integration          * Update          * Use data_dict in test          * Updates          * Update: scope of log_img          * Update: scope of log_img          * Update          * Update: Fix logging conditions          * Add tqdm bar, support for .txt dataset format          * Improve Result table Logger          * Add dataset creation in training script          * Change scope: self.wandb_run          * Add wandb-artifact:// natively          you can now use --resume with wandb run links          * Add suuport for logging dataset while training          * Cleanup          * Fix: Merge conflict          * Fix: CI tests          * Automatically use wandb config          * Fix: Resume          * Fix: CI          * Enhance: Using val_table          * More resume enhancement          * FIX : CI          * Add alias          * Get useful opt config data          * train.py cleanup          * Cleanup train.py          * more cleanup          * Cleanup| CI fix          * Reformat using PEP8          * FIX:CI          * rebase          * remove uneccesary changes          * remove uneccesary changes          * remove uneccesary changes          * remove unecessary chage from test.py          * FIX: resume from local checkpoint          * FIX:resume          * FIX:resume          * Reformat          * Performance improvement          * Fix local resume          * Fix local resume          * FIX:CI          * Fix: CI          * Imporve image logging          * (:(:Redo CI tests:):)          * Remember epochs when resuming          * Remember epochs when resuming          * Update DDP location          Potential fix for #2405          * PEP8 reformat          * 0.25 confidence threshold          * reset train.py plots syntax to previous          * reset epochs completed syntax to previous          * reset space to previous          * remove brackets          * reset comment to previous          * Update: is_coco check, remove unused code          * Remove redundant print statement          * Remove wandb imports          * remove dsviz logger from test.py          * Remove redundant change from test.py          * remove redundant changes from train.py          * reformat and improvements          * Fix typo          * Add tqdm tqdm progress when scanning files, naming improvements          Co-authored-by: Glenn Jocher <glenn.jocher@ultralytics.com> 
 from utils.loss import ComputeLoss  from utils.plots import plot_images, plot_labels, plot_results, plot_evolution  from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel from utils.wandb_logging.wandb_utils import WandbLogger, resume_and_get_id, check_wandb_config_file    logger = logging.getLogger(__name__)     def train(hyp, opt, device, tb_writer=None, wandb=None): def train(hyp, opt, device, tb_writer=None):      logger.info(colorstr('hyperparameters: ') + ', '.join(f'{k}={v}' for k, v in hyp.items()))      save_dir, epochs, batch_size, total_batch_size, weights, rank = \          Path(opt.save_dir), opt.epochs, opt.batch_size, opt.total_batch_size, opt.weights, opt.global_rank 
