      Metric-Confidence plots feature addition (#2057)          * Metric-Confidence plots feature addition          * cleanup          * Metric-Confidence plots feature addition          * cleanup          * Update run-once lines          * cleanup          * save all 4 curves to wandb 
               # Recall              recall = tpc / (n_l + 1e-16)  # recall curve             r[ci] = np.interp(-pr_score, -conf[i], recall[:, 0])  # r at pr_score, negative x, xp because xp decreases             r[ci] = np.interp(-px, -conf[i], recall[:, 0], left=0)  # negative x, xp because xp decreases                # Precision              precision = tpc / (tpc + fpc)  # precision curve             p[ci] = np.interp(-pr_score, -conf[i], precision[:, 0])  # p at pr_score             p[ci] = np.interp(-px, -conf[i], precision[:, 0], left=1)  # p at pr_score                # AP from recall-precision curve              for j in range(tp.shape[1]):                  ap[ci, j], mpre, mrec = compute_ap(recall[:, j], precision[:, j])                 if plot and (j == 0):                 if plot and j == 0:                      py.append(np.interp(px, mrec, mpre))  # precision at mAP@0.5       # Compute F1 score (harmonic mean of precision and recall)     # Compute F1 (harmonic mean of precision and recall)      f1 = 2 * p * r / (p + r + 1e-16)       if plot:         plot_pr_curve(px, py, ap, save_dir, names)         plot_pr_curve(px, py, ap, Path(save_dir) / 'PR_curve.png', names)         plot_mc_curve(px, f1, Path(save_dir) / 'F1_curve.png', names, ylabel='F1')         plot_mc_curve(px, p, Path(save_dir) / 'P_curve.png', names, ylabel='Precision')         plot_mc_curve(px, r, Path(save_dir) / 'R_curve.png', names, ylabel='Recall')       return p, r, ap, f1, unique_classes.astype('int32')     i = f1.mean(0).argmax()  # max F1 index     return p[:, i], r[:, i], ap, f1[:, i], unique_classes.astype('int32')      def compute_ap(recall, precision): 
