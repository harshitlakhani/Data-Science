      Update DDP for `torch.distributed.run` with `gloo` backend (#3680)          * Update DDP for `torch.distributed.run`          * Add LOCAL_RANK          * remove opt.local_rank          * backend="gloo|nccl"          * print          * print          * debug          * debug          * os.getenv          * gloo          * gloo          * gloo          * cleanup          * fix getenv          * cleanup          * cleanup destroy          * try nccl          * return opt          * add --local_rank          * add timeout          * add init_method          * gloo          * move destroy          * move destroy          * move print(opt) under if RANK          * destroy only RANK 0          * move destroy inside train()          * restore destroy outside train()          * update print(opt)          * cleanup          * nccl          * gloo with 60 second timeout          * update namespace printing 
     imgsz, imgsz_test = [check_img_size(x, gs) for x in opt.img_size]  # verify imgsz are gs-multiples        # DP mode     if cuda and rank == -1 and torch.cuda.device_count() > 1:     if cuda and RANK == -1 and torch.cuda.device_count() > 1:          model = torch.nn.DataParallel(model)        # SyncBatchNorm     if opt.sync_bn and cuda and rank != -1:     if opt.sync_bn and cuda and RANK != -1:          model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)          logger.info('Using SyncBatchNorm()')        # Trainloader      dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, single_cls,                                             hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect, rank=rank,                                             world_size=opt.world_size, workers=opt.workers,                                             hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect, rank=RANK,                                             workers=opt.workers,                                              image_weights=opt.image_weights, quad=opt.quad, prefix=colorstr('train: '))      mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class      nb = len(dataloader)  # number of batches      assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Possible class labels are 0-%g' % (mlc, nc, opt.data, nc - 1)        # Process 0     if rank in [-1, 0]:     if RANK in [-1, 0]:          testloader = create_dataloader(test_path, imgsz_test, batch_size * 2, gs, single_cls,                                         hyp=hyp, cache=opt.cache_images and not opt.notest, rect=True, rank=-1,                                        world_size=opt.world_size, workers=opt.workers,                                        workers=opt.workers,                                         pad=0.5, prefix=colorstr('val: '))[0]            if not opt.resume: 
